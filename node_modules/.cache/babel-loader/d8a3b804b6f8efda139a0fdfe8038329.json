{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.MessageStream = void 0;\n\nconst stream_1 = require(\"stream\");\n\nconst error_1 = require(\"../error\");\n\nconst utils_1 = require(\"../utils\");\n\nconst commands_1 = require(\"./commands\");\n\nconst compression_1 = require(\"./wire_protocol/compression\");\n\nconst constants_1 = require(\"./wire_protocol/constants\");\n\nconst MESSAGE_HEADER_SIZE = 16;\nconst COMPRESSION_DETAILS_SIZE = 9; // originalOpcode + uncompressedSize, compressorID\n\nconst kDefaultMaxBsonMessageSize = 1024 * 1024 * 16 * 4;\n/** @internal */\n\nconst kBuffer = Symbol('buffer');\n/**\n * A duplex stream that is capable of reading and writing raw wire protocol messages, with\n * support for optional compression\n * @internal\n */\n\nclass MessageStream extends stream_1.Duplex {\n  constructor() {\n    let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    super(options);\n    /** @internal */\n\n    this.isMonitoringConnection = false;\n    this.maxBsonMessageSize = options.maxBsonMessageSize || kDefaultMaxBsonMessageSize;\n    this[kBuffer] = new utils_1.BufferPool();\n  }\n\n  get buffer() {\n    return this[kBuffer];\n  }\n\n  _write(chunk, _, callback) {\n    this[kBuffer].append(chunk);\n    processIncomingData(this, callback);\n  }\n\n  _read() {\n    // NOTE: This implementation is empty because we explicitly push data to be read\n    //       when `writeMessage` is called.\n    return;\n  }\n\n  writeCommand(command, operationDescription) {\n    const agreedCompressor = operationDescription.agreedCompressor ?? 'none';\n\n    if (agreedCompressor === 'none' || !canCompress(command)) {\n      const data = command.toBin();\n      this.push(Array.isArray(data) ? Buffer.concat(data) : data);\n      return;\n    } // otherwise, compress the message\n\n\n    const concatenatedOriginalCommandBuffer = Buffer.concat(command.toBin());\n    const messageToBeCompressed = concatenatedOriginalCommandBuffer.slice(MESSAGE_HEADER_SIZE); // Extract information needed for OP_COMPRESSED from the uncompressed message\n\n    const originalCommandOpCode = concatenatedOriginalCommandBuffer.readInt32LE(12);\n    const options = {\n      agreedCompressor,\n      zlibCompressionLevel: operationDescription.zlibCompressionLevel ?? 0\n    }; // Compress the message body\n\n    (0, compression_1.compress)(options, messageToBeCompressed).then(compressedMessage => {\n      // Create the msgHeader of OP_COMPRESSED\n      const msgHeader = Buffer.alloc(MESSAGE_HEADER_SIZE);\n      msgHeader.writeInt32LE(MESSAGE_HEADER_SIZE + COMPRESSION_DETAILS_SIZE + compressedMessage.length, 0); // messageLength\n\n      msgHeader.writeInt32LE(command.requestId, 4); // requestID\n\n      msgHeader.writeInt32LE(0, 8); // responseTo (zero)\n\n      msgHeader.writeInt32LE(constants_1.OP_COMPRESSED, 12); // opCode\n      // Create the compression details of OP_COMPRESSED\n\n      const compressionDetails = Buffer.alloc(COMPRESSION_DETAILS_SIZE);\n      compressionDetails.writeInt32LE(originalCommandOpCode, 0); // originalOpcode\n\n      compressionDetails.writeInt32LE(messageToBeCompressed.length, 4); // Size of the uncompressed compressedMessage, excluding the MsgHeader\n\n      compressionDetails.writeUInt8(compression_1.Compressor[agreedCompressor], 8); // compressorID\n\n      this.push(Buffer.concat([msgHeader, compressionDetails, compressedMessage]));\n    }, error => {\n      operationDescription.cb(error);\n    });\n  }\n\n}\n\nexports.MessageStream = MessageStream; // Return whether a command contains an uncompressible command term\n// Will return true if command contains no uncompressible command terms\n\nfunction canCompress(command) {\n  const commandDoc = command instanceof commands_1.Msg ? command.command : command.query;\n  const commandName = Object.keys(commandDoc)[0];\n  return !compression_1.uncompressibleCommands.has(commandName);\n}\n\nfunction processIncomingData(stream, callback) {\n  const buffer = stream[kBuffer];\n  const sizeOfMessage = buffer.getInt32();\n\n  if (sizeOfMessage == null) {\n    return callback();\n  }\n\n  if (sizeOfMessage < 0) {\n    return callback(new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}`));\n  }\n\n  if (sizeOfMessage > stream.maxBsonMessageSize) {\n    return callback(new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}, max allowed: ${stream.maxBsonMessageSize}`));\n  }\n\n  if (sizeOfMessage > buffer.length) {\n    return callback();\n  }\n\n  const message = buffer.read(sizeOfMessage);\n  const messageHeader = {\n    length: message.readInt32LE(0),\n    requestId: message.readInt32LE(4),\n    responseTo: message.readInt32LE(8),\n    opCode: message.readInt32LE(12)\n  };\n\n  const monitorHasAnotherHello = () => {\n    if (stream.isMonitoringConnection) {\n      // Can we read the next message size?\n      const sizeOfMessage = buffer.getInt32();\n\n      if (sizeOfMessage != null && sizeOfMessage <= buffer.length) {\n        return true;\n      }\n    }\n\n    return false;\n  };\n\n  let ResponseType = messageHeader.opCode === constants_1.OP_MSG ? commands_1.BinMsg : commands_1.Response;\n\n  if (messageHeader.opCode !== constants_1.OP_COMPRESSED) {\n    const messageBody = message.subarray(MESSAGE_HEADER_SIZE); // If we are a monitoring connection message stream and\n    // there is more in the buffer that can be read, skip processing since we\n    // want the last hello command response that is in the buffer.\n\n    if (monitorHasAnotherHello()) {\n      return processIncomingData(stream, callback);\n    }\n\n    stream.emit('message', new ResponseType(message, messageHeader, messageBody));\n\n    if (buffer.length >= 4) {\n      return processIncomingData(stream, callback);\n    }\n\n    return callback();\n  }\n\n  messageHeader.fromCompressed = true;\n  messageHeader.opCode = message.readInt32LE(MESSAGE_HEADER_SIZE);\n  messageHeader.length = message.readInt32LE(MESSAGE_HEADER_SIZE + 4);\n  const compressorID = message[MESSAGE_HEADER_SIZE + 8];\n  const compressedBuffer = message.slice(MESSAGE_HEADER_SIZE + 9); // recalculate based on wrapped opcode\n\n  ResponseType = messageHeader.opCode === constants_1.OP_MSG ? commands_1.BinMsg : commands_1.Response;\n  (0, compression_1.decompress)(compressorID, compressedBuffer).then(messageBody => {\n    if (messageBody.length !== messageHeader.length) {\n      return callback(new error_1.MongoDecompressionError('Message body and message header must be the same length'));\n    } // If we are a monitoring connection message stream and\n    // there is more in the buffer that can be read, skip processing since we\n    // want the last hello command response that is in the buffer.\n\n\n    if (monitorHasAnotherHello()) {\n      return processIncomingData(stream, callback);\n    }\n\n    stream.emit('message', new ResponseType(message, messageHeader, messageBody));\n\n    if (buffer.length >= 4) {\n      return processIncomingData(stream, callback);\n    }\n\n    return callback();\n  }, error => {\n    return callback(error);\n  });\n}","map":{"version":3,"mappings":";;;;;;;AAAA;;AAGA;;AAEA;;AACA;;AACA;;AAOA;;AAEA,MAAMA,mBAAmB,GAAG,EAA5B;AACA,MAAMC,wBAAwB,GAAG,CAAjC,C,CAAoC;;AAEpC,MAAMC,0BAA0B,GAAG,OAAO,IAAP,GAAc,EAAd,GAAmB,CAAtD;AACA;;AACA,MAAMC,OAAO,GAAGC,MAAM,CAAC,QAAD,CAAtB;AAuBA;;;;;;AAKA,MAAaC,aAAb,SAAmCC,eAAnC,CAAyC;EAQvCC,cAA8C;IAAA,IAAlCC,OAAkC,uEAAF,EAAE;IAC5C,MAAMA,OAAN;IAJF;;IACA,8BAAyB,KAAzB;IAIE,KAAKC,kBAAL,GAA0BD,OAAO,CAACC,kBAAR,IAA8BP,0BAAxD;IACA,KAAKC,OAAL,IAAgB,IAAIO,kBAAJ,EAAhB;EACD;;EAES,IAANC,MAAM;IACR,OAAO,KAAKR,OAAL,CAAP;EACD;;EAEQS,MAAM,CAACC,KAAD,EAAgBC,CAAhB,EAA4BC,QAA5B,EAAsD;IACnE,KAAKZ,OAAL,EAAca,MAAd,CAAqBH,KAArB;IACAI,mBAAmB,CAAC,IAAD,EAAOF,QAAP,CAAnB;EACD;;EAEQG,KAAK,GAAW;IACvB;IACA;IACA;EACD;;EAEDC,YAAY,CACVC,OADU,EAEVC,oBAFU,EAEgC;IAE1C,MAAMC,gBAAgB,GAAGD,oBAAoB,CAACC,gBAArB,IAAyC,MAAlE;;IACA,IAAIA,gBAAgB,KAAK,MAArB,IAA+B,CAACC,WAAW,CAACH,OAAD,CAA/C,EAA0D;MACxD,MAAMI,IAAI,GAAGJ,OAAO,CAACK,KAAR,EAAb;MACA,KAAKC,IAAL,CAAUC,KAAK,CAACC,OAAN,CAAcJ,IAAd,IAAsBK,MAAM,CAACC,MAAP,CAAcN,IAAd,CAAtB,GAA4CA,IAAtD;MACA;IACD,CAPyC,CAQ1C;;;IACA,MAAMO,iCAAiC,GAAGF,MAAM,CAACC,MAAP,CAAcV,OAAO,CAACK,KAAR,EAAd,CAA1C;IACA,MAAMO,qBAAqB,GAAGD,iCAAiC,CAACE,KAAlC,CAAwCjC,mBAAxC,CAA9B,CAV0C,CAY1C;;IACA,MAAMkC,qBAAqB,GAAGH,iCAAiC,CAACI,WAAlC,CAA8C,EAA9C,CAA9B;IAEA,MAAM3B,OAAO,GAAG;MACdc,gBADc;MAEdc,oBAAoB,EAAEf,oBAAoB,CAACe,oBAArB,IAA6C;IAFrD,CAAhB,CAf0C,CAmB1C;;IACA,4BAAS5B,OAAT,EAAkBwB,qBAAlB,EAAyCK,IAAzC,CACEC,iBAAiB,IAAG;MAClB;MACA,MAAMC,SAAS,GAAGV,MAAM,CAACW,KAAP,CAAaxC,mBAAb,CAAlB;MACAuC,SAAS,CAACE,YAAV,CACEzC,mBAAmB,GAAGC,wBAAtB,GAAiDqC,iBAAiB,CAACI,MADrE,EAEE,CAFF,EAHkB,CAMf;;MACHH,SAAS,CAACE,YAAV,CAAuBrB,OAAO,CAACuB,SAA/B,EAA0C,CAA1C,EAPkB,CAO4B;;MAC9CJ,SAAS,CAACE,YAAV,CAAuB,CAAvB,EAA0B,CAA1B,EARkB,CAQY;;MAC9BF,SAAS,CAACE,YAAV,CAAuBG,yBAAvB,EAAsC,EAAtC,EATkB,CASyB;MAE3C;;MACA,MAAMC,kBAAkB,GAAGhB,MAAM,CAACW,KAAP,CAAavC,wBAAb,CAA3B;MACA4C,kBAAkB,CAACJ,YAAnB,CAAgCP,qBAAhC,EAAuD,CAAvD,EAbkB,CAayC;;MAC3DW,kBAAkB,CAACJ,YAAnB,CAAgCT,qBAAqB,CAACU,MAAtD,EAA8D,CAA9D,EAdkB,CAcgD;;MAClEG,kBAAkB,CAACC,UAAnB,CAA8BC,yBAAWzB,gBAAX,CAA9B,EAA4D,CAA5D,EAfkB,CAe8C;;MAChE,KAAKI,IAAL,CAAUG,MAAM,CAACC,MAAP,CAAc,CAACS,SAAD,EAAYM,kBAAZ,EAAgCP,iBAAhC,CAAd,CAAV;IACD,CAlBH,EAmBEU,KAAK,IAAG;MACN3B,oBAAoB,CAAC4B,EAArB,CAAwBD,KAAxB;IACD,CArBH;EAuBD;;AA1EsC;;AAAzCE,sC,CA6EA;AACA;;AACA,SAAS3B,WAAT,CAAqBH,OAArB,EAAsD;EACpD,MAAM+B,UAAU,GAAG/B,OAAO,YAAYgC,cAAnB,GAAyBhC,OAAO,CAACA,OAAjC,GAA2CA,OAAO,CAACiC,KAAtE;EACA,MAAMC,WAAW,GAAGC,MAAM,CAACC,IAAP,CAAYL,UAAZ,EAAwB,CAAxB,CAApB;EACA,OAAO,CAACJ,qCAAuBU,GAAvB,CAA2BH,WAA3B,CAAR;AACD;;AAED,SAASrC,mBAAT,CAA6ByC,MAA7B,EAAoD3C,QAApD,EAA8E;EAC5E,MAAMJ,MAAM,GAAG+C,MAAM,CAACvD,OAAD,CAArB;EACA,MAAMwD,aAAa,GAAGhD,MAAM,CAACiD,QAAP,EAAtB;;EAEA,IAAID,aAAa,IAAI,IAArB,EAA2B;IACzB,OAAO5C,QAAQ,EAAf;EACD;;EAED,IAAI4C,aAAa,GAAG,CAApB,EAAuB;IACrB,OAAO5C,QAAQ,CAAC,IAAI8C,uBAAJ,CAAoB,yBAAyBF,aAAa,EAA1D,CAAD,CAAf;EACD;;EAED,IAAIA,aAAa,GAAGD,MAAM,CAACjD,kBAA3B,EAA+C;IAC7C,OAAOM,QAAQ,CACb,IAAI8C,uBAAJ,CACE,yBAAyBF,aAAa,kBAAkBD,MAAM,CAACjD,kBAAkB,EADnF,CADa,CAAf;EAKD;;EAED,IAAIkD,aAAa,GAAGhD,MAAM,CAAC+B,MAA3B,EAAmC;IACjC,OAAO3B,QAAQ,EAAf;EACD;;EAED,MAAM+C,OAAO,GAAGnD,MAAM,CAACoD,IAAP,CAAYJ,aAAZ,CAAhB;EACA,MAAMK,aAAa,GAAkB;IACnCtB,MAAM,EAAEoB,OAAO,CAAC3B,WAAR,CAAoB,CAApB,CAD2B;IAEnCQ,SAAS,EAAEmB,OAAO,CAAC3B,WAAR,CAAoB,CAApB,CAFwB;IAGnC8B,UAAU,EAAEH,OAAO,CAAC3B,WAAR,CAAoB,CAApB,CAHuB;IAInC+B,MAAM,EAAEJ,OAAO,CAAC3B,WAAR,CAAoB,EAApB;EAJ2B,CAArC;;EAOA,MAAMgC,sBAAsB,GAAG,MAAK;IAClC,IAAIT,MAAM,CAACU,sBAAX,EAAmC;MACjC;MACA,MAAMT,aAAa,GAAGhD,MAAM,CAACiD,QAAP,EAAtB;;MACA,IAAID,aAAa,IAAI,IAAjB,IAAyBA,aAAa,IAAIhD,MAAM,CAAC+B,MAArD,EAA6D;QAC3D,OAAO,IAAP;MACD;IACF;;IACD,OAAO,KAAP;EACD,CATD;;EAWA,IAAI2B,YAAY,GAAGL,aAAa,CAACE,MAAd,KAAyBtB,kBAAzB,GAAkCQ,iBAAlC,GAA2CA,mBAA9D;;EACA,IAAIY,aAAa,CAACE,MAAd,KAAyBtB,yBAA7B,EAA4C;IAC1C,MAAM0B,WAAW,GAAGR,OAAO,CAACS,QAAR,CAAiBvE,mBAAjB,CAApB,CAD0C,CAG1C;IACA;IACA;;IACA,IAAImE,sBAAsB,EAA1B,EAA8B;MAC5B,OAAOlD,mBAAmB,CAACyC,MAAD,EAAS3C,QAAT,CAA1B;IACD;;IAED2C,MAAM,CAACc,IAAP,CAAY,SAAZ,EAAuB,IAAIH,YAAJ,CAAiBP,OAAjB,EAA0BE,aAA1B,EAAyCM,WAAzC,CAAvB;;IAEA,IAAI3D,MAAM,CAAC+B,MAAP,IAAiB,CAArB,EAAwB;MACtB,OAAOzB,mBAAmB,CAACyC,MAAD,EAAS3C,QAAT,CAA1B;IACD;;IACD,OAAOA,QAAQ,EAAf;EACD;;EAEDiD,aAAa,CAACS,cAAd,GAA+B,IAA/B;EACAT,aAAa,CAACE,MAAd,GAAuBJ,OAAO,CAAC3B,WAAR,CAAoBnC,mBAApB,CAAvB;EACAgE,aAAa,CAACtB,MAAd,GAAuBoB,OAAO,CAAC3B,WAAR,CAAoBnC,mBAAmB,GAAG,CAA1C,CAAvB;EACA,MAAM0E,YAAY,GAAGZ,OAAO,CAAC9D,mBAAmB,GAAG,CAAvB,CAA5B;EACA,MAAM2E,gBAAgB,GAAGb,OAAO,CAAC7B,KAAR,CAAcjC,mBAAmB,GAAG,CAApC,CAAzB,CAlE4E,CAoE5E;;EACAqE,YAAY,GAAGL,aAAa,CAACE,MAAd,KAAyBtB,kBAAzB,GAAkCQ,iBAAlC,GAA2CA,mBAA1D;EACA,8BAAWsB,YAAX,EAAyBC,gBAAzB,EAA2CtC,IAA3C,CACEiC,WAAW,IAAG;IACZ,IAAIA,WAAW,CAAC5B,MAAZ,KAAuBsB,aAAa,CAACtB,MAAzC,EAAiD;MAC/C,OAAO3B,QAAQ,CACb,IAAI8C,+BAAJ,CAA4B,yDAA5B,CADa,CAAf;IAGD,CALW,CAOZ;IACA;IACA;;;IACA,IAAIM,sBAAsB,EAA1B,EAA8B;MAC5B,OAAOlD,mBAAmB,CAACyC,MAAD,EAAS3C,QAAT,CAA1B;IACD;;IACD2C,MAAM,CAACc,IAAP,CAAY,SAAZ,EAAuB,IAAIH,YAAJ,CAAiBP,OAAjB,EAA0BE,aAA1B,EAAyCM,WAAzC,CAAvB;;IAEA,IAAI3D,MAAM,CAAC+B,MAAP,IAAiB,CAArB,EAAwB;MACtB,OAAOzB,mBAAmB,CAACyC,MAAD,EAAS3C,QAAT,CAA1B;IACD;;IACD,OAAOA,QAAQ,EAAf;EACD,CApBH,EAqBEiC,KAAK,IAAG;IACN,OAAOjC,QAAQ,CAACiC,KAAD,CAAf;EACD,CAvBH;AAyBD","names":["MESSAGE_HEADER_SIZE","COMPRESSION_DETAILS_SIZE","kDefaultMaxBsonMessageSize","kBuffer","Symbol","MessageStream","stream_1","constructor","options","maxBsonMessageSize","utils_1","buffer","_write","chunk","_","callback","append","processIncomingData","_read","writeCommand","command","operationDescription","agreedCompressor","canCompress","data","toBin","push","Array","isArray","Buffer","concat","concatenatedOriginalCommandBuffer","messageToBeCompressed","slice","originalCommandOpCode","readInt32LE","zlibCompressionLevel","then","compressedMessage","msgHeader","alloc","writeInt32LE","length","requestId","constants_1","compressionDetails","writeUInt8","compression_1","error","cb","exports","commandDoc","commands_1","query","commandName","Object","keys","has","stream","sizeOfMessage","getInt32","error_1","message","read","messageHeader","responseTo","opCode","monitorHasAnotherHello","isMonitoringConnection","ResponseType","messageBody","subarray","emit","fromCompressed","compressorID","compressedBuffer"],"sources":["C:\\Users\\anshs\\OneDrive\\Documents\\Code\\WebDevelopement\\portfolioPersonal\\node_modules\\mongodb\\src\\cmap\\message_stream.ts"],"sourcesContent":["import { Duplex, DuplexOptions } from 'stream';\n\nimport type { BSONSerializeOptions, Document } from '../bson';\nimport { MongoDecompressionError, MongoParseError } from '../error';\nimport type { ClientSession } from '../sessions';\nimport { BufferPool, Callback } from '../utils';\nimport { BinMsg, MessageHeader, Msg, Response, WriteProtocolMessageType } from './commands';\nimport {\n  compress,\n  Compressor,\n  CompressorName,\n  decompress,\n  uncompressibleCommands\n} from './wire_protocol/compression';\nimport { OP_COMPRESSED, OP_MSG } from './wire_protocol/constants';\n\nconst MESSAGE_HEADER_SIZE = 16;\nconst COMPRESSION_DETAILS_SIZE = 9; // originalOpcode + uncompressedSize, compressorID\n\nconst kDefaultMaxBsonMessageSize = 1024 * 1024 * 16 * 4;\n/** @internal */\nconst kBuffer = Symbol('buffer');\n\n/** @internal */\nexport interface MessageStreamOptions extends DuplexOptions {\n  maxBsonMessageSize?: number;\n}\n\n/** @internal */\nexport interface OperationDescription extends BSONSerializeOptions {\n  started: number;\n  cb: Callback<Document>;\n  command: boolean;\n  documentsReturnedIn?: string;\n  noResponse: boolean;\n  raw: boolean;\n  requestId: number;\n  session?: ClientSession;\n  socketTimeoutOverride?: boolean;\n  agreedCompressor?: CompressorName;\n  zlibCompressionLevel?: number;\n  $clusterTime?: Document;\n}\n\n/**\n * A duplex stream that is capable of reading and writing raw wire protocol messages, with\n * support for optional compression\n * @internal\n */\nexport class MessageStream extends Duplex {\n  /** @internal */\n  maxBsonMessageSize: number;\n  /** @internal */\n  [kBuffer]: BufferPool;\n  /** @internal */\n  isMonitoringConnection = false;\n\n  constructor(options: MessageStreamOptions = {}) {\n    super(options);\n    this.maxBsonMessageSize = options.maxBsonMessageSize || kDefaultMaxBsonMessageSize;\n    this[kBuffer] = new BufferPool();\n  }\n\n  get buffer(): BufferPool {\n    return this[kBuffer];\n  }\n\n  override _write(chunk: Buffer, _: unknown, callback: Callback<Buffer>): void {\n    this[kBuffer].append(chunk);\n    processIncomingData(this, callback);\n  }\n\n  override _read(/* size */): void {\n    // NOTE: This implementation is empty because we explicitly push data to be read\n    //       when `writeMessage` is called.\n    return;\n  }\n\n  writeCommand(\n    command: WriteProtocolMessageType,\n    operationDescription: OperationDescription\n  ): void {\n    const agreedCompressor = operationDescription.agreedCompressor ?? 'none';\n    if (agreedCompressor === 'none' || !canCompress(command)) {\n      const data = command.toBin();\n      this.push(Array.isArray(data) ? Buffer.concat(data) : data);\n      return;\n    }\n    // otherwise, compress the message\n    const concatenatedOriginalCommandBuffer = Buffer.concat(command.toBin());\n    const messageToBeCompressed = concatenatedOriginalCommandBuffer.slice(MESSAGE_HEADER_SIZE);\n\n    // Extract information needed for OP_COMPRESSED from the uncompressed message\n    const originalCommandOpCode = concatenatedOriginalCommandBuffer.readInt32LE(12);\n\n    const options = {\n      agreedCompressor,\n      zlibCompressionLevel: operationDescription.zlibCompressionLevel ?? 0\n    };\n    // Compress the message body\n    compress(options, messageToBeCompressed).then(\n      compressedMessage => {\n        // Create the msgHeader of OP_COMPRESSED\n        const msgHeader = Buffer.alloc(MESSAGE_HEADER_SIZE);\n        msgHeader.writeInt32LE(\n          MESSAGE_HEADER_SIZE + COMPRESSION_DETAILS_SIZE + compressedMessage.length,\n          0\n        ); // messageLength\n        msgHeader.writeInt32LE(command.requestId, 4); // requestID\n        msgHeader.writeInt32LE(0, 8); // responseTo (zero)\n        msgHeader.writeInt32LE(OP_COMPRESSED, 12); // opCode\n\n        // Create the compression details of OP_COMPRESSED\n        const compressionDetails = Buffer.alloc(COMPRESSION_DETAILS_SIZE);\n        compressionDetails.writeInt32LE(originalCommandOpCode, 0); // originalOpcode\n        compressionDetails.writeInt32LE(messageToBeCompressed.length, 4); // Size of the uncompressed compressedMessage, excluding the MsgHeader\n        compressionDetails.writeUInt8(Compressor[agreedCompressor], 8); // compressorID\n        this.push(Buffer.concat([msgHeader, compressionDetails, compressedMessage]));\n      },\n      error => {\n        operationDescription.cb(error);\n      }\n    );\n  }\n}\n\n// Return whether a command contains an uncompressible command term\n// Will return true if command contains no uncompressible command terms\nfunction canCompress(command: WriteProtocolMessageType) {\n  const commandDoc = command instanceof Msg ? command.command : command.query;\n  const commandName = Object.keys(commandDoc)[0];\n  return !uncompressibleCommands.has(commandName);\n}\n\nfunction processIncomingData(stream: MessageStream, callback: Callback<Buffer>): void {\n  const buffer = stream[kBuffer];\n  const sizeOfMessage = buffer.getInt32();\n\n  if (sizeOfMessage == null) {\n    return callback();\n  }\n\n  if (sizeOfMessage < 0) {\n    return callback(new MongoParseError(`Invalid message size: ${sizeOfMessage}`));\n  }\n\n  if (sizeOfMessage > stream.maxBsonMessageSize) {\n    return callback(\n      new MongoParseError(\n        `Invalid message size: ${sizeOfMessage}, max allowed: ${stream.maxBsonMessageSize}`\n      )\n    );\n  }\n\n  if (sizeOfMessage > buffer.length) {\n    return callback();\n  }\n\n  const message = buffer.read(sizeOfMessage);\n  const messageHeader: MessageHeader = {\n    length: message.readInt32LE(0),\n    requestId: message.readInt32LE(4),\n    responseTo: message.readInt32LE(8),\n    opCode: message.readInt32LE(12)\n  };\n\n  const monitorHasAnotherHello = () => {\n    if (stream.isMonitoringConnection) {\n      // Can we read the next message size?\n      const sizeOfMessage = buffer.getInt32();\n      if (sizeOfMessage != null && sizeOfMessage <= buffer.length) {\n        return true;\n      }\n    }\n    return false;\n  };\n\n  let ResponseType = messageHeader.opCode === OP_MSG ? BinMsg : Response;\n  if (messageHeader.opCode !== OP_COMPRESSED) {\n    const messageBody = message.subarray(MESSAGE_HEADER_SIZE);\n\n    // If we are a monitoring connection message stream and\n    // there is more in the buffer that can be read, skip processing since we\n    // want the last hello command response that is in the buffer.\n    if (monitorHasAnotherHello()) {\n      return processIncomingData(stream, callback);\n    }\n\n    stream.emit('message', new ResponseType(message, messageHeader, messageBody));\n\n    if (buffer.length >= 4) {\n      return processIncomingData(stream, callback);\n    }\n    return callback();\n  }\n\n  messageHeader.fromCompressed = true;\n  messageHeader.opCode = message.readInt32LE(MESSAGE_HEADER_SIZE);\n  messageHeader.length = message.readInt32LE(MESSAGE_HEADER_SIZE + 4);\n  const compressorID = message[MESSAGE_HEADER_SIZE + 8];\n  const compressedBuffer = message.slice(MESSAGE_HEADER_SIZE + 9);\n\n  // recalculate based on wrapped opcode\n  ResponseType = messageHeader.opCode === OP_MSG ? BinMsg : Response;\n  decompress(compressorID, compressedBuffer).then(\n    messageBody => {\n      if (messageBody.length !== messageHeader.length) {\n        return callback(\n          new MongoDecompressionError('Message body and message header must be the same length')\n        );\n      }\n\n      // If we are a monitoring connection message stream and\n      // there is more in the buffer that can be read, skip processing since we\n      // want the last hello command response that is in the buffer.\n      if (monitorHasAnotherHello()) {\n        return processIncomingData(stream, callback);\n      }\n      stream.emit('message', new ResponseType(message, messageHeader, messageBody));\n\n      if (buffer.length >= 4) {\n        return processIncomingData(stream, callback);\n      }\n      return callback();\n    },\n    error => {\n      return callback(error);\n    }\n  );\n}\n"]},"metadata":{},"sourceType":"script"}